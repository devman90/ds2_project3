{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Activity Classification with Various Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 제출기한: 2020년 9월 4일 금요일 오후 11시 59분 59초까지\n",
    "- 제출방법 - 이메일 (여러 번 제출할 경우 마지막 제출 사용)\n",
    "  - 메일주소: `hcs.lab.2019@gmail.com`\n",
    "  - 메일제목: `Group0 ML project 3` (Group1, Group2, ... 식으로 Group명을 바꿔주세요)\n",
    "  - 제출 내용: `project_3.ipynb` 의 [3번 Cell](#Various-Classifiers-with-Feature-Extractor-and-Preprocessor) (Various Classifiers with Feature Extractor and Preprocessor) 의 코드를 이메일 본문에 삽입해서 제출\n",
    "    - **%%%%% 주의사항 %%%%%**\n",
    "    - **3번 Cell을 제외한 다른 부분의 코드는 제출하지 않고, 채점도 되지 않습니다.**\n",
    "    - **3번 Cell의 `lr_clf`, `lda_clf`, `rf_clf`, `svm_clf`, `boost_clf` 변수들의 이름을 수정하시면 안됩니다. (채점시 해당 변수들을 Classifier로 사용 예정)**\n",
    "  - 채점방식은 가장 아래의 [Scoring](#Scoring) 부분을 참고해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과제 목표: 여러 가지 종류의 Classifier를 이용한 Activity Recognition\n",
    "- 과제 방식\n",
    "  1. 여러 가지 종류의 Classifier를 만듭니다.\n",
    "    - `Logistic Regression`, `Linear Discriminant Analysis`, `Random Forest`, `Support Vector Machines`, `Boosting with Decision Trees` 의 5가지 방식을 사용합니다. 각각 `lr_clf`, `lda_clf`, `rf_clf`, `svm_clf`, `boost_clf` 변수에 해당하고, **각 변수는 해당하는 방식으로 최종 Classification을 진행해야합니다.**\n",
    "  2. 각 Classifier에 대해 Cross Validation을 이용하여 Test macro f1 score가 가장 높게 나올만한 Feature, Preprocessor, Hyperparameter를 구합니다.\n",
    "  4. Pipeline을 이용하여 FeatureExtracting과 Preprocessing, Classification을 해주는 Classifier들을 만들어 제출합니다. (채점시 `lr_clf`, `lda_clf`, `rf_clf`, `svm_clf`, `boost_clf` 변수들을 Classifier로 사용 예정)\n",
    "- 채점 기준\n",
    "  - 제출한 3번 Cell의 5가지 분류기들을 이용하여 각각 train data를 학습시키고, test data에 대해 macro f1 score를 측정합니다.\n",
    "  - train data는 train.pkl로 주어진 7명의 데이터이고, test data는 주어지지 않은 2명의 데이터입니다.\n",
    "  - f1 score는 precision과 recall의 조화평균입니다.\n",
    "  - f1 score는 각 Motion마다 구해집니다. 전체 데이터에 대한 f1 score를 구하는 방법에는 크게 micro, macro, weighted 3가지 방식이 있습니다.\n",
    "    - micro f1 score: 전체 데이터에 대한 precision과 recall의 조화평균으로 accuracy와 같습니다.\n",
    "    - macro f1 score: 각 Motion별 f1 score의 평균\n",
    "    - weighted f1 score: 각 Motion의 sample수에 비례하게 weight를 준 평균\n",
    "  - project_3의 경우 5가지 분류기의 macro f1 score의 평균값을 이용해 평가합니다.\n",
    "  - 최고 score 팀은 16점, 최저 score 팀은 11점이고, 그 사이의 팀들은 score에 비례하여 점수를 매깁니다.\n",
    "  - (ex. 3팀, 5가지 분류기의 평균 macro f1 score: [0.7, 0.6, 0.5] => 점수: [16점, 13.5점, 11점])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Input Data Description\n",
    "<img src=\"example.png\" width='500px'>\n",
    "<div style='text-align:center'>Figure 1. Data Example (2 samples)</div><br/>\n",
    "<div>1. Figure 1과 같이 손목에 달려있는 가속도계의 x, y, z축 가속도 정보를 이용하여 행동을 예측한다.</div>\n",
    "<div>2. 주어진 Train Data(data/train.pkl)는 총 7명의 데이터이다. (총 13940개의 데이터 샘플)</div>\n",
    "<div>3. 각 데이터 샘플은 Subject, Data, Motion으로 이루어지고 의미는 아래와 같다.</div>\n",
    "<div style='text-indent:20px'>Subject: 샘플을 수집한 실험자의 id, type은 int (분류할 때 feature (predictor) 로 이용하지 않는다)</div>\n",
    "<div style='text-indent:20px'>Data: (500, 3) Shape의 Numpy array (1초당 100개씩 5초간 x, y, z축의 가속도값을 측정)</div>\n",
    "<div style='text-indent:20px'>Motion: 행동의 종류, type은 string (ex. 'walking')</div>\n",
    "<div>4. Subject 정보는 분류에 이용되지 않는다.</div>\n",
    "<div>5. Subject 정보를 이용하여 train data와 validation data를 나눌 수 있다.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Data</th>\n",
       "      <th>Motion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-2.115489959716797, 2.9105000495910645, 8.15...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-3.5734200477600098, 3.9679501056671143, 10....</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-1.7668700218200684, 11.98840045928955, 1.08...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject                                               Data   Motion\n",
       "0        3  [[-2.115489959716797, 2.9105000495910645, 8.15...  ironing\n",
       "1        3  [[-3.5734200477600098, 3.9679501056671143, 10....  ironing\n",
       "2        3  [[-1.7668700218200684, 11.98840045928955, 1.08...  ironing"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아래와 같은 방식으로 train data를 load할 수 있다.\n",
    "import pickle\n",
    "\n",
    "with open('data/train.pkl', 'rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Data</th>\n",
       "      <th>Motion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-2.115489959716797, 2.9105000495910645, 8.15...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-3.5734200477600098, 3.9679501056671143, 10....</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-1.7668700218200684, 11.98840045928955, 1.08...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-4.2224202156066895, 9.517740249633789, 2.67...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[[-6.610869884490967, 4.498380184173584, 7.815...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13935</th>\n",
       "      <td>7</td>\n",
       "      <td>[[-1.8887399435043335, 2.340670108795166, 8.27...</td>\n",
       "      <td>rope jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13936</th>\n",
       "      <td>7</td>\n",
       "      <td>[[-5.959249973297119, -7.587969779968262, 1.86...</td>\n",
       "      <td>rope jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13937</th>\n",
       "      <td>7</td>\n",
       "      <td>[[4.046329975128174, 14.204400062561035, -0.56...</td>\n",
       "      <td>rope jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13938</th>\n",
       "      <td>7</td>\n",
       "      <td>[[-14.82509994506836, 37.050201416015625, -8.1...</td>\n",
       "      <td>rope jumping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13939</th>\n",
       "      <td>7</td>\n",
       "      <td>[[4.965579986572266, 2.059380054473877, -8.590...</td>\n",
       "      <td>rope jumping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13940 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject                                               Data  \\\n",
       "0            3  [[-2.115489959716797, 2.9105000495910645, 8.15...   \n",
       "1            3  [[-3.5734200477600098, 3.9679501056671143, 10....   \n",
       "2            3  [[-1.7668700218200684, 11.98840045928955, 1.08...   \n",
       "3            3  [[-4.2224202156066895, 9.517740249633789, 2.67...   \n",
       "4            3  [[-6.610869884490967, 4.498380184173584, 7.815...   \n",
       "...        ...                                                ...   \n",
       "13935        7  [[-1.8887399435043335, 2.340670108795166, 8.27...   \n",
       "13936        7  [[-5.959249973297119, -7.587969779968262, 1.86...   \n",
       "13937        7  [[4.046329975128174, 14.204400062561035, -0.56...   \n",
       "13938        7  [[-14.82509994506836, 37.050201416015625, -8.1...   \n",
       "13939        7  [[4.965579986572266, 2.059380054473877, -8.590...   \n",
       "\n",
       "             Motion  \n",
       "0           ironing  \n",
       "1           ironing  \n",
       "2           ironing  \n",
       "3           ironing  \n",
       "4           ironing  \n",
       "...             ...  \n",
       "13935  rope jumping  \n",
       "13936  rope jumping  \n",
       "13937  rope jumping  \n",
       "13938  rope jumping  \n",
       "13939  rope jumping  \n",
       "\n",
       "[13940 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9가 하나의 Group을 담당하기엔 너무 작은 것 같다. 7로 변경하자\n",
    "df_train.loc[df_train['Subject'] == 9, 'Subject'] = 7\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data 종류는 ['Subject', 'Data', 'Motion']가 있습니다\n",
      "\n",
      "Subject 개수: 13940\n",
      "X 개수: 13940\n",
      "y 개수: 13940\n",
      "\n",
      "Subject는 int, Data는 numpy.ndarray, Motion은 string 값을 가집니다\n",
      "type(subjects[0]): <class 'numpy.int64'>\n",
      "type(X[0]): <class 'numpy.ndarray'>\n",
      "type(y[0]): <class 'numpy.str_'>\n",
      "\n",
      "X는 (500, 3) 형태의 np.ndarray입니다\n",
      "\n",
      "y (motion) classes: ['Nordic walking', 'ascending stairs', 'cycling', 'descending stairs', 'ironing', 'lying', 'rope jumping', 'running', 'sitting', 'standing', 'vacuum cleaning', 'walking']\n",
      "\n",
      "Subject들: {3, 4, 5, 6, 7, 8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Data 종류는 {list(df_train.columns)}가 있습니다')\n",
    "print()\n",
    "\n",
    "subjects, X, y = df_train.Subject, df_train.Data, df_train.Motion\n",
    "print(f'Subject 개수: {len(subjects)}')\n",
    "print(f'X 개수: {len(X)}')\n",
    "print(f'y 개수: {len(y)}')\n",
    "print()\n",
    "\n",
    "print('Subject는 int, Data는 numpy.ndarray, Motion은 string 값을 가집니다')\n",
    "print(f'type(subjects[0]): {type(subjects[0])}')\n",
    "print(f'type(X[0]): {type(X[0])}')\n",
    "print(f'type(y[0]): {type(y[0])}')\n",
    "print()\n",
    "\n",
    "print(f'X는 {X[0].shape} 형태의 np.ndarray입니다')\n",
    "print()\n",
    "\n",
    "print(f'y (motion) classes: {sorted(list(set(y)))}')\n",
    "print()\n",
    "\n",
    "print(f'Subject들: {set(subjects)}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "## Various Classifiers with Feature Extractor and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "#  Logistic Regression, Linear Discriminant Analysis, Random Forest, Support Vector Machines, Boosting with Decision Trees\n",
    "#  위 5가지 방식으로 동작하는 Classifier를 만들어주세요.\n",
    "#  (각각 변수명은 `lr_clf`, `lda_clf`, `rf_clf`, `svm_clf`, `boost_clf`입니다.)\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "#  1. project_2.ipynb를 참고하시면 도움이 될 것 같습니다.\n",
    "#\n",
    "#  2. 각 Classifier마다 서로 다른 Feature, Preprocessor를 사용하셔도 됩니다.\n",
    "#    - project_3.ipynb 가장 아래 부분의 Scoring 파트가 잘 동작하고,\n",
    "#    - 각 Classifier가 문제에서 제시된 알고리즘으로 분류를 한다면 나머지 부분은 원하는 방식으로 작성하시면 됩니다.\n",
    "#      (ex. `lr_clf` 인데 내부 로직은 Random Forest를 사용한다거나 하시면 안됩니다. )\n",
    "# ---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fft, stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def preprocess(X): # Wrapper of extract_features\n",
    "    '''\n",
    "    Preprocess multiple samples\n",
    "    input\n",
    "        X : (n, 500, 3)\n",
    "    output\n",
    "        X_processed : (n, p)\n",
    "    '''\n",
    "    X_processed = []\n",
    "    xyz = lambda f: [v + '__' + f for v in 'xyzm']\n",
    "\n",
    "    for i, X_sample in enumerate(X):\n",
    "        mag = np.sqrt(np.sum(X_sample ** 2, axis=1)).reshape(-1, 1)\n",
    "        X_sample = np.hstack([X_sample, mag])\n",
    "        \n",
    "        extracted = []\n",
    "        columns = []\n",
    "\n",
    "        columns += xyz('std')\n",
    "        extracted.append(X_sample.std(axis=0))\n",
    "\n",
    "        columns += xyz('cid_ce_norm')\n",
    "        s = np.std(X_sample, axis=0)\n",
    "        x = (X_sample - np.mean(X_sample, axis=0)) / s\n",
    "        diff = np.diff(x, axis=0)\n",
    "        extracted.append(np.sqrt(np.sum(diff**2, axis=0)))\n",
    "\n",
    "        columns += xyz('number_crossing_0')\n",
    "        positive = X_sample > 0\n",
    "        diff = np.diff(positive, axis=0)\n",
    "\n",
    "        count = [\n",
    "            np.where(diff[:, 0])[0].size,\n",
    "            np.where(diff[:, 1])[0].size,\n",
    "            np.where(diff[:, 2])[0].size,\n",
    "            np.where(diff[:, 3])[0].size,\n",
    "        ]\n",
    "        extracted.append(count)\n",
    "\n",
    "        columns += xyz('number_crossing_mean')\n",
    "        positive = X_sample > np.mean(X_sample, axis=0)\n",
    "        diff = np.diff(positive, axis=0)\n",
    "        count = [\n",
    "            np.where(diff[:, 0])[0].size,\n",
    "            np.where(diff[:, 1])[0].size,\n",
    "            np.where(diff[:, 2])[0].size,\n",
    "            np.where(diff[:, 3])[0].size,\n",
    "        ]\n",
    "        extracted.append(count)\n",
    "\n",
    "        # quantiles \n",
    "        for p in [0.1, 0.5, 0.9]: \n",
    "            columns += xyz('percentile_' + str(p))\n",
    "            extracted.append(np.quantile(X_sample, p, axis=0))\n",
    "\n",
    "        columns += xyz('count_above_mean')\n",
    "        extracted.append(np.sum(X_sample > np.mean(X_sample, axis=0), axis=0))\n",
    "\n",
    "        columns += xyz('count_above_0')\n",
    "        extracted.append(np.sum(X_sample > 0, axis=0))\n",
    "\n",
    "        columns += xyz('abs_energy')\n",
    "        extracted.append((X_sample ** 2).sum(axis=0))\n",
    "\n",
    "        columns += xyz('absolute_sum_of_changes')\n",
    "        extracted.append(np.sum(np.abs(np.diff(X_sample, axis=0)), axis=0))\n",
    "\n",
    "        fft_abs = np.abs(fft.rfft(X_sample, axis=0))[1:]\n",
    "\n",
    "        columns += xyz('fft_energy')\n",
    "        extracted.append((fft_abs ** 2).sum(axis=0))\n",
    "\n",
    "        columns += xyz('fft_centroid')\n",
    "        extracted.append(np.sum(fft_abs * np.arange(len(fft_abs)).reshape(-1, 1), axis=0) / np.sum(fft_abs, axis=0))\n",
    "\n",
    "        columns += xyz('fft_variance')\n",
    "        moment2 = np.sum(fft_abs * np.arange(len(fft_abs)).reshape(-1, 1) ** 2, axis=0) / np.sum(fft_abs, axis=0)\n",
    "        centroids = np.sum(fft_abs * np.arange(len(fft_abs)).reshape(-1, 1), axis=0) / np.sum(fft_abs, axis=0)\n",
    "        fft_var = moment2 - centroids ** 2\n",
    "        extracted.append(fft_var)\n",
    "\n",
    "        columns += xyz('spectral_entropy')\n",
    "        extracted.append(stats.entropy(fft_abs))\n",
    "\n",
    "        X_processed.append(np.hstack(extracted))\n",
    "\n",
    "    df = pd.DataFrame(data=np.array(X_processed), columns=columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "lr_clf = Pipeline([  # Classifier using Logistic Regression\n",
    "    ('feature_extractor', FunctionTransformer(preprocess)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=250, solver='newton-cg', C=0.01)),\n",
    "])\n",
    "\n",
    "lda_clf = Pipeline([  # Classifier using Linear Discriminant Analysis\n",
    "    ('feature_extractor', FunctionTransformer(preprocess)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LinearDiscriminantAnalysis(solver='svd')),\n",
    "])\n",
    "\n",
    "rf_clf = Pipeline([  # Classifier using Random Forest\n",
    "    ('feature_extractor', FunctionTransformer(preprocess)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=400, criterion=\"gini\", ccp_alpha=0.0, max_depth=24)),\n",
    "])\n",
    "\n",
    "svm_clf = Pipeline([  # Classifier using Support Vector Machines\n",
    "    ('feature_extractor', FunctionTransformer(preprocess)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVC(C=0.6, kernel='rbf')),\n",
    "])\n",
    "\n",
    "boost_clf = Pipeline([  # Classifier using Boosting with Decision Tree\n",
    "    ('feature_extractor', FunctionTransformer(preprocess)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=16), \n",
    "        learning_rate=1.0, \n",
    "        n_estimators=512)\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lr_clf  # Set classifier to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avarage macro f1 score: 0.7414417359550974\n",
      "Avarage macro f1 score: 0.7761027800627894\n",
      "Avarage macro f1 score: 0.7258576125317971\n",
      "Avarage macro f1 score: 0.7160844646811767\n",
      "Avarage macro f1 score: 0.7428753963852621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut\n",
    "\n",
    "clf_list = [lr_clf, lda_clf, rf_clf, svm_clf, boost_clf]\n",
    "#mask = subjects != 9\n",
    "#X, y, subjects = X[mask], y[mask], subjects[mask]\n",
    "for clf in clf_list:\n",
    "    cv_result = cross_validate(clf, X, y, groups=subjects, scoring='f1_macro', cv=LeaveOneGroupOut())\n",
    "    average_test_score = np.mean(cv_result['test_score'])\n",
    "    print(f'Avarage macro f1 score: {average_test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = rf_clf  # Set classifier to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'classifier__criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "\n",
    "param_grid = {\n",
    "    'classifier__criterion': ['gini', 'entropy'],  # Example param_grid for rf_clf\n",
    "}\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    cv=LeaveOneGroupOut(),\n",
    "    scoring='f1_macro'\n",
    ")\n",
    "\n",
    "grid_search_cv.fit(X, y, groups=subjects)\n",
    "\n",
    "print(f'Best params: {grid_search_cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scoring\n",
    "- 아래 코드들은 실제 채점시 사용될 코드입니다.\n",
    "  - 제출하신 Cell의 코드를 `project_3.ipynb`에 덮어쓰고 Restart & Run All을 실행하여 나온 결과를 사용합니다.\n",
    "- `test.pkl`에는 `train.pkl`에 없는 다른 2명의 subject 데이터가 들어있습니다.\n",
    "- 프로젝트를 하실 때에는 `test.pkl`이 없으므로 아래 코드가 실행되지 않는게 정상입니다.\n",
    "- 채점은 아래 코드로 이루어진다는 것을 참고하시면 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Motion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[2.43859, 7.02674, 5.74905], [2.58814, 6.9873...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[2.52346, 6.31869, 7.25372], [2.02206, 5.2595...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-3.03257, 8.39546, 1.27492], [-3.17651, 8.28...</td>\n",
       "      <td>ironing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Data   Motion\n",
       "0  [[2.43859, 7.02674, 5.74905], [2.58814, 6.9873...  ironing\n",
       "1  [[2.52346, 6.31869, 7.25372], [2.02206, 5.2595...  ironing\n",
       "2  [[-3.03257, 8.39546, 1.27492], [-3.17651, 8.28...  ironing"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/train.pkl', 'rb') as f:\n",
    "    df_train = pickle.load(f)\n",
    "\n",
    "with open('data/test.pkl', 'rb') as f:\n",
    "    df_test = pickle.load(f)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13940,) (5007,) (13940,) (5007,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = df_train.Data, df_test.Data, df_train.Motion, df_test.Motion\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_scores = []\n",
    "clfs = [lr_clf, lda_clf, rf_clf, svm_clf, boost_clf]\n",
    "for clf in clfs:\n",
    "    y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(f1_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
